{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import ast \n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "different = {'Peace':0, 'Affection':1, 'Esteem':2, 'Anticipation':3, 'Engagement':4,\n",
    "             'Confidence':5, 'Happiness':6, 'Pleasure':7, 'Excitement':8,'Surprise':9,\n",
    "             'Sympathy':10, 'Doubt/Confusion':11, 'Disconnection':12, 'Fatigue':13, 'Embarrassment':14,\n",
    "             'Yearning':15, 'Disapproval':16, 'Aversion':17, 'Annoyance':18, 'Anger':19, \n",
    "             'Sensitivity':20, 'Sadness':21, 'Disquietment':22, 'Fear':23, 'Pain':24, 'Suffering':25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_emotion(lst):\n",
    "    # When given a list of possible emotions from emotic dataset, \n",
    "    # it will only take the one that matches the subset\n",
    "    \n",
    "    for emotion in [lst].strip('][').split(', '):\n",
    "                    emotion = emotion.replace(\"'\",\"\")\n",
    "                    try:\n",
    "                        if emotion in emotions: # Checking if one of the emotions is in the smaller list of emotions we created\n",
    "                            return emotion\n",
    "                            break\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(train_file, test_file):\n",
    "    train = pd.read_csv(train_file, usecols=['Index', 'Folder', 'Filename', 'Image Size'] )\n",
    "    test = pd.read_csv(test_file, usecols=['Index', 'Folder', 'Filename', 'Image Size'])\n",
    "    \n",
    "    X_train = []\n",
    "\n",
    "    Y_train = train[['BBox','Categorical_Labels', 'Gender', 'Age']]\n",
    "\n",
    "    X_test = test[['Index', 'Folder', 'Filename', 'Image Size']]\n",
    "    Y_test = test[['BBox','Categorical_Labels', 'Gender', 'Age']]\n",
    "\n",
    "    Y_train = to_categorical(Y_train['Categorical_Labels'])\n",
    "    Y_test = to_categorical(Y_test['Categorical_Labels'])\n",
    "\n",
    "    for idx in tqdm(range(len(train)), desc='Loading train data...'):\n",
    "        try:\n",
    "            x = get_photo(train[idx])\n",
    "            x.append(img)\n",
    "            y.append()\n",
    "        except:\n",
    "            pass\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo(file, idx):\n",
    "    folder = file['Folder'][idx]\n",
    "    filename = file['Filename'][idx]\n",
    "    cwd = os.getcwd() + '/Data'\n",
    "\n",
    "    img = image.load_img(f'{cwd}/emotic/{folder}/{filename}', target_size=(350,350,1), grayscale=True)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255.0   \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(file, idx):\n",
    "    bb = file['BBox'][idx]\n",
    "    emotion = file['Categorical_Labels'][idx]\n",
    "    gender = file['Gender'][idx]\n",
    "    age = file['Age'][idx]\n",
    "    folder = file['Folder'][idx]\n",
    "    filename = file['Filename'][idx]\n",
    "   \n",
    "    # Bounding Box locations\n",
    "    img = get_photo(file, idx)\n",
    "    x, y, w, h = ast.literal_eval(bb)\n",
    "       \n",
    "\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0,0,0), 2)\n",
    "        \n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/emotic_pre/train.csv')\n",
    "predictions(data, 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}